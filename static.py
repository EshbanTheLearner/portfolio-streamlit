info = {
    "name": "Eshban Suleman",
    "intro": """I'm a Data Scientist with 3+ years of broad-based experience in building data-intensive applications and overcoming complex architectural issues. Proficient in predictive modelling, large-scale data processing, NLP and statistical analysis, as well as scripting languages like Python. Capable of creating, developing, testing and deploying highly adaptive diverse services to translate business and functional qualifications into substantial deliverables.
                \nI like to read books. I particularly enjoy reading self-help and non-finction books. I also enjoy watching TV shows and Movies. May favorite genres are aSci-Fi, Psychological Thrillers, Fantasy and Adventure. I'm a sports fanatic too and I also play a number of indoor and outdoor sports like Cricket, Table Tennis, Basketball and Chess. I also like to spend my time learning about new and fascinating things.ðŸ˜„""",
    "photo": {"path": "photo.jpg", "width": 150},
    "mobile": "+92-304-4455675",
    "email": "eshban9492@gmail.com",
    "resume": "pdf/CV_Eshban.pdf",
    "medium": "https://medium.com/@eshban9492",
    "publication_url": "https://eshban9492.medium.com/",
    "skills": [
        "Exploratory Data Analysis", "Feature Engineering", "Data Analysis",
        "Predictive Modeling", "Data Visualization", "Machine Learning",
        "Deep Learning", "Natural Language Processing", "Time Series Analysis",
        "A/B Testing", "Web APIs (Flask, FastAPI)", "SQL (BigQuery, PostgreSQL)", 
        "Git", "Streamlit",
        "MLOps (DVC, MLFlow, Docker, GitHub Actions etc.)",
        "Python (Pandas, Numpy, Scikit-Learn, Tensorflow, PyTorch etc.)",
        "AWS (S3, EC2, Lambda, Sagemaker, API Gateway etc.)",
    ]
}

responsibilities = [
    """- **Lead the research and development** of a Semantic Search Engine""",
    """- **Developed tests and benchmarks** to evaluate the performance of our ML models""",
    """- **Improved the performance** of our production ML model by **49%** in one case and by **6%** in another by **improving Data Quality** and **Hyperparameter Pptimization**""",
    """- **Decreased the latency** of our API by **40%** by optimizing the architecture for inference time""",
    """- **Reduced costs** of our APIs by **72%** in one case and **68%** in another by developing an **Automated Self-Replacing Spot Server System** in AWS""",
    """- **Brought deployment time down** by **83%** by implementing a robust **CI/CD Pipeline** using **DVC, Docker, GitHub Actions and AWS Elastic Beanstalk**""",
    """- **Designed and developed data pipelines** to fetch data and update our online ML models""",
    """- **Took additional responsibilities** such as **interviewing, onboarding, mentoring, planning product roadmaps, delegating tasks** etc."""
]

stack = [
    """- **Python** (Numpy, Pandas, Flask, Gensim, Transformers, FAISS, Tensorflow, PyTorch)""",
    """- **Database** (PostgreSQL, BigQuery, Redis)""",
    """- **MLOps** (Git, DVC, Docker, GitHub Actions, AWS Elastic Beanstalk)""",
    """- **AWS** (Sagemaker, S3, EC2, Lambda, API Gateway etc.)"""
]

skills = {
    "Advance": [
        """- Python Programming (Numpy, Pandas)""", """- WebAPIs (Flask, FastAPI)""", """- SQL (PostgreSQL, BigQuery)""",
        """- Exploratory Data Analysis""", """- Feature Engineering""", """- Preditive Modeling""",
        """- Machine Learning (Scikit-Learn, Statsmodel)""", """- Deep Learning (Tensorflow, Keras, PyTorch)""", """- Natural Language Processing (NLTK, SpaCy, Transformers)""",
        """- Data Visualization (Matplotlib, Seaborn, Plotly, Streamlit)""", """- AWS (Sagemaker, S3, EC2, Lambda etc.)""", """- MLOps (Git, DVC, Docker, GitHub Actions etc)"""
    ],
    "Intermediate": [
        """- Time Series Analysis""", """- A/B Testing""", """- Risk Minimization""",
        """- Computer Vision (Detection, Classification, Segmentation etc)""", """- Apache Spark""", """- GCP (Storage, CE, GKE, BigQuery etc.)""",
        """""", """""", """""",
        """""", """""", """""",
    ],
    "Beginner": [
        """- Apache Aiflow""", """- Apache Kafka""", """- Causal Inference""",
        """- Graph Analysis""", """""", """""",
        """""", """""", """""",
        """""", """""", """""",
    ]
}

projects_info = {
    "Reginald von Doom": [
        """- Reginald von Doom is a system that summarizes legal or financial documents in an easy to understand form""",
        """- Used Google's T5 model to summarize documents""",
        """- Created a simple UI in streamlit""",
        """- Deployed to Streamlit cloud"""
    ],
    "MRE": [
        """- It is a simple movie recommendation engine""",
        """- Analyzed the TMDB data and created features in form of tags (description, cast, crew)""",
        """- Used Sentence Transformer model to extract feature embeddings and cosine similarity to find similar content""",
        """- Created a simple UI in Streamlit and deployed the app to the cloud"""
    ]
}

embeds = {
    "linkedin": """<script src="https://platform.linkedin.com/badges/js/profile.js" async defer type="text/javascript"></script><div class="badge-base LI-profile-badge" data-locale="en_US" data-size="medium" data-theme="light" data-type="VERTICAL" data-vanity="eshban-suleman-624a49113" data-version="v1"><a class="badge-base__link LI-simple-link" href="https://pk.linkedin.com/in/eshban-suleman-624a49113?trk=profile-badge"></a></div>""",
    "twitter-profile": """<a href="https://twitter.com/EshbanSuleman?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @EshbanSuleman</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>""",
    "twitter-feed": """<a class="twitter-timeline" href="https://twitter.com/EshbanSuleman?ref_src=twsrc%5Etfw">Tweets by EshbanSuleman</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>""",
    "medium": """<div style="overflow-y: scroll; height:500px;"> <div id="retainable-rss-embed" data-rss="https://medium.com/feed/@eshban9492" data-maxcols="3" data-layout="grid" data-poststyle="inline" data-readmore="Read the rest" data-buttonclass="btn btn-primary" data-offset="0"></div></div> <script src="https://www.twilik.com/assets/retainable/rss-embed/retainable-rss-embed.js"></script>"""
}

vids = {
    "mre-vid": "./media/vids/mre.mp4",
    "reginald-vid": "./media/vids/reginald.mp4"
}

imgs = [
    "./media/imgs/1.jpg",
    "./media/imgs/2.jpg",
    "./media/imgs/3.jpg",
    "./media/imgs/4.jpg",
    "./media/imgs/5.jpg",
    "./media/imgs/6.jpg",
]

imgs_titles = [
    "Data Science Professional",
    "Data Engineering, Big Data, and Machine Learning on GCP",
    "Applied Data Science",
    "Mathematics for Machine Learning",
    "Tensorflow in Practice",
    "Deep Learning"
]

imgs_captions = [
    "Databricks Academy ([Verify](https://academy.databricks.com/award/completion/35e13f64-01d3-3c38-93ec-146c978ba2fe/view-ext))",
    "Google Cloud ([Verify](https://www.coursera.org/account/accomplishments/specialization/certificate/BTX3N9JPQ5AW))",
    "IBM ([Verify](https://www.coursera.org/account/accomplishments/specialization/FRZJAJNXW6UN))",
    "Imperial College London ([Verify](https://www.coursera.org/account/accomplishments/specialization/JLNS4URRRENR))",
    "Deeplearning.ai ([Verify](https://www.coursera.org/account/accomplishments/specialization/MCZZWYTTM3QP))",
    "Deeplearning.ai ([Verify](https://www.coursera.org/account/accomplishments/specialization/QCNQP6JC97Q9))"
]

link = "https://github.com/EshbanTheLearner/Certifications"